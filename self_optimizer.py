# =====================================================
# ICT Trading Bot â€” SMC Parameter Optimizer v4.0
# (Narrative â†’ POI â†’ Trigger Threshold Optimizer)
# =====================================================
#
# v4.0 UYARLAMA: Gate sistemi kaldÄ±rÄ±ldÄ±.
# Yeni mimari: Narrative (4H yapÄ±) â†’ POI (OB+FVG+Likidite) â†’ Trigger
#
# MANTIK:
#   Bot, veritabanÄ±ndaki WON/LOST iÅŸlemleri analiz ederek
#   ICT strateji motorundaki geometrik ve hacimsel eÅŸikleri
#   (threshold) otomatik optimize eder.
#
# OPTÄ°MÄ°ZE EDÄ°LEN PARAMETRELER:
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚ Parametre                        â”‚ Katman     â”‚ GÃ¼venli AralÄ±k â”‚
# â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
# â”‚ displacement_min_body_ratio      â”‚ Trigger    â”‚ 0.40 â€“ 0.75    â”‚
# â”‚ displacement_min_size_pct        â”‚ Trigger    â”‚ 0.002 â€“ 0.010  â”‚
# â”‚ displacement_atr_multiplier      â”‚ Trigger    â”‚ 1.00 â€“ 2.50    â”‚
# â”‚ bos_min_displacement             â”‚ Narrative  â”‚ 0.001 â€“ 0.006  â”‚
# â”‚ fvg_min_size_pct                 â”‚ POI        â”‚ 0.0003 â€“ 0.004 â”‚
# â”‚ fvg_max_age_candles              â”‚ POI        â”‚ 10 â€“ 40        â”‚
# â”‚ liquidity_equal_tolerance        â”‚ POI        â”‚ 0.0003 â€“ 0.003 â”‚
# â”‚ ob_body_ratio_min                â”‚ POI        â”‚ 0.25 â€“ 0.65    â”‚
# â”‚ ob_max_age_candles               â”‚ POI        â”‚ 15 â€“ 50        â”‚
# â”‚ swing_lookback                   â”‚ YapÄ±sal    â”‚ 3 â€“ 8          â”‚
# â”‚ default_sl_pct                   â”‚ Risk       â”‚ 0.008 â€“ 0.025  â”‚
# â”‚ poi_max_distance_pct             â”‚ POI        â”‚ 0.005 â€“ 0.020  â”‚
# â”‚ min_rr_ratio                     â”‚ Risk       â”‚ 1.20 â€“ 3.00    â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#
# Ã–ÄRENME ALGORÄ°TMASI:
#   1. Son N kapanmÄ±ÅŸ (WON/LOST) iÅŸlemleri Ã§ek
#   2. LOST iÅŸlemlerdeki ortak zayÄ±flÄ±klarÄ± tespit et
#      â†’ ZayÄ±f displacement? KÃ¼Ã§Ã¼k FVG? Sahte sweep?
#   3. WON iÅŸlemlerin ortak kalite Ã¶zelliklerini bul
#      â†’ BÃ¼yÃ¼k FVG, gÃ¼Ã§lÃ¼ gÃ¶vde, yÃ¼ksek hacim
#   4. EÅŸik deÄŸerlerini veri odaklÄ± kÃ¼Ã§Ã¼k adÄ±mlarla ayarla
#   5. Her deÄŸiÅŸikliÄŸi ayrÄ±ntÄ±lÄ± logla
#
# GÃœVENLÄ°K:
#   - Her parametrenin min/max sÄ±nÄ±rÄ± var (boundary protection)
#   - Tek seferde max %10 deÄŸiÅŸiklik
#   - Minimum 20 kapanmÄ±ÅŸ iÅŸlem gerekli
#   - Death spiral korumasÄ± (emergency mode + bounds clamp)
# =====================================================

import logging
import json
from datetime import datetime
from database import (
    get_completed_signals, get_performance_summary,
    get_component_performance, save_bot_param, get_bot_param,
    add_optimization_log, get_all_bot_params, get_loss_analysis,
    get_confluence_profitability_analysis, get_entry_mode_performance,
    get_htf_bias_accuracy, get_optimization_logs
)
from config import ICT_PARAMS, OPTIMIZER_CONFIG

logger = logging.getLogger("ICT-Bot.Optimizer")


class SelfOptimizer:
    """
    SMC Parameter Optimizer v4.1 â€” Target-Based Adaptive Optimizer.

    WON/LOST iÅŸlem verilerinden Ã¶ÄŸrenerek ICT strateji motorunun
    geometrik ve hacimsel eÅŸik deÄŸerlerini otomatik optimize eder.

    v4.1 FARKLAR (v4.0'dan):
      1. TARGET-BASED: TÃ¼m koÅŸullar hedef WR (%55) bazlÄ±
      2. COMPONENT-AWARE: Hangi trigger tipi kÃ¶tÃ¼ ise o katman Ã¶ncelikli
      3. MAX 4 CHANGE: DÃ¶ngÃ¼ baÅŸÄ±na max 4 parametre deÄŸiÅŸir
      4. ROLLBACK: Son deÄŸiÅŸiklik WR'yi dÃ¼ÅŸÃ¼rdÃ¼yse geri alÄ±nÄ±r
      5. PRIORITY: Parametreler etki bÃ¼yÃ¼klÃ¼ÄŸÃ¼ne gÃ¶re sÄ±ralanÄ±r

    Mimari:
      1. BileÅŸen performansÄ±nÄ± analiz et (SWEEP %47, MSS %33, DISP %100)
      2. KÃ¶tÃ¼ bileÅŸenlere ait parametreleri Ã¶nceliklendir
      3. Rollback kontrolÃ¼ (son deÄŸiÅŸiklik kÃ¶tÃ¼leÅŸtirdi mi?)
      4. Hedef-adaptif adÄ±m hesapla (hedefe uzaksa bÃ¼yÃ¼k, yakÄ±nsa kÃ¼Ã§Ã¼k)
      5. Max 4 en Ã¶ncelikli parametreyi deÄŸiÅŸtir

    BileÅŸen â†’ Parametre Ä°liÅŸkisi:
      SWEEP/REJECTION â†’ liquidity_equal_tolerance, swing_lookback
      MSS            â†’ bos_min_displacement, ob_body_ratio_min
      DISPLACEMENT   â†’ displacement_*, fvg_*
      HTF_BIAS       â†’ bos_min_displacement, swing_lookback
      POI_ZONE       â†’ poi_max_distance_pct, ob_max_age_candles, fvg_max_age_candles
      (Risk)         â†’ default_sl_pct, min_rr_ratio
    """

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  BÄ°LEÅEN â†’ PARAMETRE HARÄ°TASI
    #  Hangi bileÅŸen kÃ¶tÃ¼yse hangi parametreler optimize edilecek
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    COMPONENT_PARAM_MAP = {
        "SWEEP": ["liquidity_equal_tolerance", "swing_lookback"],
        "REJECTION": ["liquidity_equal_tolerance", "displacement_min_body_ratio"],
        "MSS": ["bos_min_displacement", "ob_body_ratio_min", "swing_lookback"],
        "DISPLACEMENT": ["displacement_min_body_ratio", "displacement_atr_multiplier", "displacement_min_size_pct"],
        "HTF_BIAS": ["bos_min_displacement", "swing_lookback"],
        "POI_ZONE": ["poi_max_distance_pct", "ob_max_age_candles", "fvg_max_age_candles", "fvg_min_size_pct"],
    }

    # Her dÃ¶ngÃ¼de max kaÃ§ parametre deÄŸiÅŸebilir
    MAX_CHANGES_PER_CYCLE = 4

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  PARAMETRE REJÄ°STRÄ°SÄ°
    #  Her parametrenin gÃ¼venli sÄ±nÄ±rlarÄ±, grubu ve aÃ§Ä±klamasÄ±
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    PARAM_REGISTRY = {
        # â”€â”€ Trigger KatmanÄ±: Displacement Kalitesi â”€â”€
        "displacement_min_body_ratio": {
            "bounds": (0.40, 0.75),
            "group": "trigger",
            "desc": "Displacement mumunun minimum gÃ¶vde/fitil oranÄ±",
        },
        "displacement_min_size_pct": {
            "bounds": (0.002, 0.010),
            "group": "trigger",
            "desc": "Minimum displacement boyutu (fiyatÄ±n %'si)",
        },
        "displacement_atr_multiplier": {
            "bounds": (1.00, 2.50),
            "group": "trigger",
            "desc": "Displacement ATR Ã§arpanÄ± (ÅŸiddet Ã¶lÃ§Ã¼sÃ¼)",
        },

        # â”€â”€ Narrative KatmanÄ±: YapÄ± KÄ±rÄ±lÄ±mÄ± â”€â”€
        "bos_min_displacement": {
            "bounds": (0.001, 0.006),
            "group": "narrative",
            "desc": "BOS iÃ§in minimum kÄ±rÄ±lÄ±m oranÄ±",
        },

        # â”€â”€ POI KatmanÄ±: FVG Kalitesi â”€â”€
        "fvg_min_size_pct": {
            "bounds": (0.0003, 0.004),
            "group": "poi",
            "desc": "Minimum FVG boyutu (fiyatÄ±n %'si)",
        },
        "fvg_max_age_candles": {
            "bounds": (10, 40),
            "group": "poi",
            "desc": "FVG geÃ§erlilik sÃ¼resi (mum sayÄ±sÄ±)",
        },

        # â”€â”€ POI KatmanÄ±: Likidite Sweep Hassasiyeti â”€â”€
        "liquidity_equal_tolerance": {
            "bounds": (0.0003, 0.003),
            "group": "poi",
            "desc": "Equal high/low toleransÄ± (milimetrik hassasiyet)",
        },

        # â”€â”€ POI KatmanÄ±: Order Block & Swing â”€â”€
        "ob_body_ratio_min": {
            "bounds": (0.25, 0.65),
            "group": "poi",
            "desc": "Order Block mumunun minimum gÃ¶vde oranÄ±",
        },
        "ob_max_age_candles": {
            "bounds": (15, 50),
            "group": "poi",
            "desc": "Order Block geÃ§erlilik sÃ¼resi (mum sayÄ±sÄ±)",
        },
        "swing_lookback": {
            "bounds": (3, 8),
            "group": "structural",
            "desc": "Swing noktasÄ± tespiti bakÄ±ÅŸ penceresi",
        },

        # â”€â”€ POI KatmanÄ±: Confluence Mesafe â”€â”€
        "poi_max_distance_pct": {
            "bounds": (0.005, 0.020),
            "group": "poi",
            "desc": "POI bÃ¶lgesine max uzaklÄ±k eÅŸiÄŸi (%)",
        },

        # â”€â”€ Risk: SL / RR â”€â”€
        "default_sl_pct": {
            "bounds": (0.008, 0.025),
            "group": "risk",
            "desc": "Fallback SL yÃ¼zdesi (yapÄ±sal SL bulunamazsa)",
        },
        "min_rr_ratio": {
            "bounds": (1.20, 3.00),
            "group": "risk",
            "desc": "Minimum Risk:Reward oranÄ± eÅŸiÄŸi",
        },
    }

    GROUP_DESCRIPTIONS = {
        "trigger": "Trigger KatmanÄ± â€” Displacement kalitesi ve momentum",
        "narrative": "Narrative KatmanÄ± â€” 4H yapÄ± analizi (BOS/CHoCH)",
        "poi": "POI KatmanÄ± â€” OB, FVG, Likidite confluence kalitesi",
        "structural": "YapÄ±sal â€” Swing noktasÄ± tespiti",
        "risk": "Risk YÃ¶netimi â€” SL ve RR eÅŸikleri",
    }

    def __init__(self):
        self.learning_rate = OPTIMIZER_CONFIG.get("learning_rate", 0.03)
        self.max_change_pct = OPTIMIZER_CONFIG.get("max_param_change_pct", 0.10)
        self.min_trades = OPTIMIZER_CONFIG.get("min_trades_for_optimization", 20)
        self.target_win_rate = OPTIMIZER_CONFIG.get("win_rate_target", 0.55)
        self._last_trade_count = 0
        # Rollback tracking: son optimizasyon anÄ±ndaki WR
        self._last_optimization_wr = None
        self._last_optimization_changes = []
        logger.info("SMC Parameter Optimizer v4.1 baÅŸlatÄ±ldÄ± â€” Target-Based Adaptive Optimization")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  BAÅLANGIÃ‡ GÃœVENLÄ°K KONTROLÃœ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def enforce_bounds_on_startup(self):
        """
        BaÅŸlangÄ±Ã§ta tÃ¼m DB parametrelerini sÄ±nÄ±rlar iÃ§ine zorla.
        Death spiral sonrasÄ± kurtarma mekanizmasÄ±.
        SÄ±nÄ±r dÄ±ÅŸÄ± parametreler varsayÄ±lan deÄŸerlerine sÄ±fÄ±rlanÄ±r.
        """
        all_params = get_all_bot_params()
        reset_count = 0

        for param_name, registry in self.PARAM_REGISTRY.items():
            min_b, max_b = registry["bounds"]
            current_val = all_params.get(param_name)

            if current_val is None:
                continue

            try:
                current_val = float(current_val)
            except (TypeError, ValueError):
                continue

            if current_val < min_b or current_val > max_b:
                default = ICT_PARAMS.get(param_name, current_val)
                logger.warning(
                    f"ğŸ”„ {param_name} sÄ±nÄ±r dÄ±ÅŸÄ±: {current_val} â†’ {default} "
                    f"(izin: {min_b}â€“{max_b})"
                )
                save_bot_param(param_name, default, default)
                reset_count += 1

        if reset_count:
            logger.info(f"ğŸ”„ {reset_count} parametre sÄ±nÄ±r dÄ±ÅŸÄ±nda bulundu ve sÄ±fÄ±rlandÄ±")
        else:
            logger.info("âœ… TÃ¼m SMC parametreleri sÄ±nÄ±rlar iÃ§inde")

        return reset_count

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  ANA OPTÄ°MÄ°ZASYON DÃ–NGÃœSÃœ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def run_optimization(self):
        """
        Ana optimizasyon dÃ¶ngÃ¼sÃ¼ â€” app.py tarafÄ±ndan her 30dk Ã§aÄŸrÄ±lÄ±r.

        v4.1 AkÄ±ÅŸ:
          1. Yeterli veri kontrolÃ¼ (min 20 kapanmÄ±ÅŸ iÅŸlem)
          2. ROLLBACK: Son deÄŸiÅŸiklikler WR'yi dÃ¼ÅŸÃ¼rdÃ¼yse geri al
          3. BÄ°LEÅEN ANALÄ°ZÄ°: Hangi trigger tipi kaybettiriyor?
          4. Ã–NCELÄ°KLEME: KÃ¶tÃ¼ bileÅŸenlere ait parametreler Ã¶nce
          5. TÃœM parametreleri hesapla ama MAX 4 UYGULANIR
          6. Seans/HTF bilgi analizi
        """
        logger.info("ğŸ”„ SMC Optimizer v4.1 â€” Optimizasyon dÃ¶ngÃ¼sÃ¼ baÅŸlatÄ±lÄ±yor...")

        stats = get_performance_summary()
        total_trades = stats["total_trades"]

        if total_trades < self.min_trades:
            logger.info(
                f"Yeterli iÅŸlem yok ({total_trades}/{self.min_trades}), "
                f"optimizasyon atlanÄ±yor."
            )
            return {
                "status": "SKIPPED",
                "reason": (
                    f"TamamlanmÄ±ÅŸ (WON/LOST) iÅŸlem sayÄ±sÄ±: {total_trades} â€” "
                    f"minimum {self.min_trades} gerekli"
                ),
                "changes": [],
                "total_trades_analyzed": total_trades,
                "win_rate": stats["win_rate"],
            }

        # â•â•â• VERÄ° HAVUZU OLUÅTUR â•â•â•
        pool = self._build_trade_pool()

        logger.info(
            f"ğŸ“Š Veri havuzu: {pool['total']} iÅŸlem | "
            f"WR: {pool['win_rate']:.1f}% | "
            f"Ort kazanÃ§: +{pool['avg_win_pnl']:.2f}% | "
            f"Ort kayÄ±p: -{pool['avg_loss_pnl']:.2f}% | "
            f"GerÃ§ek RR: {pool['realized_rr']:.2f}"
        )

        changes = []

        # â•â•â• ADIM 1: ROLLBACK KONTROLÃœ â•â•â•
        rollback_changes = self._check_rollback(pool, stats)
        changes.extend(rollback_changes)

        # â•â•â• ADIM 2: ACÄ°L MOD (%0 WR + 3+ kayÄ±p) â•â•â•
        if pool["win_rate"] == 0 and len(pool["losers"]) >= 3:
            emergency = self._emergency_mode(pool, stats)
            changes.extend(emergency)

        # Rollback veya acil mod aktifse normal optimizasyonu atla
        if changes:
            self._post_optimization(changes, pool, stats, total_trades)
            return {
                "status": "COMPLETED",
                "total_trades_analyzed": total_trades,
                "win_rate": stats["win_rate"],
                "changes": changes,
            }

        # â•â•â• ADIM 3: BÄ°LEÅEN PERFORMANS ANALÄ°ZÄ° â•â•â•
        comp_perf = get_component_performance()
        priority_params = self._get_priority_params(comp_perf, pool)

        logger.info(f"ğŸ“Š BileÅŸen bazlÄ± Ã¶ncelik sÄ±rasÄ±: {[p['param'] for p in priority_params[:6]]}")

        # â•â•â• ADIM 4: TÃœM DEÄÄ°ÅÄ°KLÄ°KLERÄ° HESAPLA â•â•â•
        already_changed = set()
        all_candidates = []

        # Her katmandan deÄŸiÅŸiklik adaylarÄ±nÄ± topla
        all_candidates.extend(self._optimize_displacement(pool, stats, already_changed))
        all_candidates.extend(self._optimize_fvg(pool, stats, already_changed))
        all_candidates.extend(self._optimize_liquidity(pool, stats, already_changed))
        all_candidates.extend(self._optimize_structural(pool, stats, already_changed))
        all_candidates.extend(self._optimize_risk(pool, stats, already_changed))
        all_candidates.extend(self._optimize_poi_confluence(pool, stats, already_changed))
        all_candidates.extend(self._optimize_narrative(pool, stats, already_changed))

        # â•â•â• ADIM 5: Ã–NCELÄ°KLEME + MAX 4 LÄ°MÄ°T â•â•â•
        changes = self._select_top_changes(all_candidates, priority_params)

        # â•â•â• ADIM 6: BÄ°LGÄ° ANALÄ°ZLERÄ° â•â•â•
        self._log_session_analysis(pool)
        self._log_htf_bias_analysis()
        self._log_component_analysis(comp_perf)

        # â•â•â• SONUÃ‡ â•â•â•
        self._post_optimization(changes, pool, stats, total_trades)

        return {
            "status": "COMPLETED",
            "total_trades_analyzed": total_trades,
            "win_rate": stats["win_rate"],
            "changes": changes,
        }

    def _post_optimization(self, changes, pool, stats, total_trades):
        """Optimizasyon sonrasÄ±: logla ve state'i kaydet."""
        if changes:
            logger.info(
                f"âœ… SMC Optimizasyon tamamlandÄ±: {len(changes)} parametre gÃ¼ncellendi "
                f"(max {self.MAX_CHANGES_PER_CYCLE})"
            )
            for c in changes:
                logger.info(
                    f"   â†’ {c['param']}: {c['old']} â†’ {c['new']} "
                    f"[{c.get('group', '?')}] priority={c.get('priority', '?')}"
                )
        else:
            logger.info("â„¹ï¸ Optimizasyon: TÃ¼m parametreler optimal aralÄ±kta veya hedefte")

        # Rollback tracking iÃ§in state kaydet
        self._last_optimization_wr = pool["win_rate"]
        self._last_optimization_changes = [
            {"param": c["param"], "old": c["old"], "new": c["new"]}
            for c in changes
        ]
        self._last_trade_count = total_trades

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  ROLLBACK KONTROLÃœ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _check_rollback(self, pool, stats):
        """
        Son optimizasyondan sonra WR dÃ¼ÅŸtÃ¼yse â†’ deÄŸiÅŸiklikleri geri al.

        MantÄ±k:
          - Son opt. WR'si biliniyorsa ve ÅŸu anki WR 3+ puan dÃ¼ÅŸtÃ¼yse
          - Son deÄŸiÅŸtirilen parametreleri eski deÄŸerlerine dÃ¶ndÃ¼r
          - En son 1 dÃ¶ngÃ¼ geri alÄ±nÄ±r (zincirleme rollback yok)
        """
        changes = []

        if self._last_optimization_wr is None or not self._last_optimization_changes:
            return changes

        current_wr = pool["win_rate"]
        last_wr = self._last_optimization_wr
        wr_drop = last_wr - current_wr

        # WR 3+ puan dÃ¼ÅŸtÃ¼yse rollback
        if wr_drop >= 3.0 and len(pool["completed"]) >= self.min_trades + 2:
            logger.warning(
                f"ğŸ”™ ROLLBACK: WR {last_wr:.1f}% â†’ {current_wr:.1f}% "
                f"({wr_drop:.1f} puan dÃ¼ÅŸÃ¼ÅŸ) â€” son {len(self._last_optimization_changes)} "
                f"deÄŸiÅŸiklik geri alÄ±nÄ±yor"
            )

            for prev_change in self._last_optimization_changes:
                param = prev_change["param"]
                old_val = prev_change["old"]  # Geri dÃ¶nÃ¼lecek deÄŸer
                current_val = get_bot_param(param, ICT_PARAMS.get(param))

                reason = (
                    f"ğŸ”™ ROLLBACK: WR {wr_drop:.1f} puan dÃ¼ÅŸtÃ¼ "
                    f"({last_wr:.1f}%â†’{current_wr:.1f}%), "
                    f"{param} {current_val} â†’ {old_val} geri alÄ±ndÄ±"
                )

                default_val = ICT_PARAMS.get(param, old_val)
                save_bot_param(param, old_val, default_val)
                add_optimization_log(param, current_val, old_val, reason,
                                     current_wr, current_wr, stats["total_trades"])

                registry = self.PARAM_REGISTRY.get(param, {})
                changes.append({
                    "param": param,
                    "old": current_val,
                    "new": old_val,
                    "reason": reason,
                    "bounds": list(registry.get("bounds", (0, 0))),
                    "group": registry.get("group", "?"),
                    "priority": "ROLLBACK",
                })

                logger.info(f"ğŸ”™ {param}: {current_val} â†’ {old_val} (rollback)")

            # Rollback sonrasÄ± state temizle (zincirleme rollback engeli)
            self._last_optimization_wr = None
            self._last_optimization_changes = []

        return changes

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  BÄ°LEÅEN BAZLI Ã–NCELÄ°KLEME
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _get_priority_params(self, comp_perf, pool):
        """
        BileÅŸen performansÄ±na gÃ¶re parametreleri Ã¶nceliklendir.

        MantÄ±k:
          1. Her bileÅŸenin WR'sini al (SWEEP %47, MSS %33, vb.)
          2. WR'si en dÃ¼ÅŸÃ¼k bileÅŸenin parametrelerine en yÃ¼ksek Ã¶ncelik ver
          3. Risk parametreleri her zaman orta Ã¶ncelikli (her zaman relevant)

        Returns:
            SÄ±ralÄ± liste: [{"param": "...", "priority_score": float, "reason": "..."}, ...]
        """
        target_wr = self.target_win_rate * 100
        param_priorities = {}

        # BileÅŸen bazlÄ± Ã¶ncelikleme
        for comp_name, comp_data in comp_perf.items():
            comp_wr = comp_data.get("win_rate", 50)
            comp_total = comp_data.get("total", 0)

            if comp_total < 3:
                continue  # Yetersiz veri

            # Hedeften uzaklÄ±k = Ã¶ncelik puanÄ± (yÃ¼ksek = Ã¶ncelikli)
            gap = target_wr - comp_wr  # Pozitif = kÃ¶tÃ¼ performans

            # Bu bileÅŸene baÄŸlÄ± parametreleri bul
            mapped_params = self.COMPONENT_PARAM_MAP.get(comp_name, [])
            for param in mapped_params:
                if param not in param_priorities:
                    param_priorities[param] = {
                        "param": param,
                        "priority_score": 0,
                        "reasons": [],
                    }
                # En kÃ¶tÃ¼ bileÅŸenin gap'ini kullan (birden fazla bileÅŸen aynÄ± parametreyi etkileyebilir)
                param_priorities[param]["priority_score"] = max(
                    param_priorities[param]["priority_score"], gap
                )
                param_priorities[param]["reasons"].append(
                    f"{comp_name}:{comp_wr:.0f}%"
                )

        # Risk parametreleri her zaman orta Ã¶ncelik
        for risk_param in ["default_sl_pct", "min_rr_ratio"]:
            if risk_param not in param_priorities:
                param_priorities[risk_param] = {
                    "param": risk_param,
                    "priority_score": (target_wr - pool["win_rate"]) * 0.5,
                    "reasons": ["risk-always-relevant"],
                }

        # SÄ±rala: en yÃ¼ksek priority_score en Ã¶nce
        sorted_params = sorted(
            param_priorities.values(),
            key=lambda x: -x["priority_score"]
        )

        return sorted_params

    def _select_top_changes(self, all_candidates, priority_params):
        """
        TÃ¼m aday deÄŸiÅŸikliklerden max MAX_CHANGES_PER_CYCLE kadarÄ±nÄ± seÃ§.

        SeÃ§im kriterleri:
          1. BileÅŸen bazlÄ± Ã¶ncelik sÄ±rasÄ±na gÃ¶re (kÃ¶tÃ¼ bileÅŸen = yÃ¼ksek Ã¶ncelik)
          2. AynÄ± bileÅŸenden birden fazla parametre seÃ§me (Ã§eÅŸitlilik)
          3. Acil mod deÄŸiÅŸiklikleri her zaman dahil
        """
        if not all_candidates:
            return []

        # Priority map oluÅŸtur
        priority_map = {p["param"]: p["priority_score"] for p in priority_params}

        # Her adaya Ã¶ncelik puanÄ± ata
        for candidate in all_candidates:
            candidate["priority"] = priority_map.get(candidate["param"], 0)

        # Ã–nceliÄŸe gÃ¶re sÄ±rala
        all_candidates.sort(key=lambda c: -c["priority"])

        # Max limit uygula + grup Ã§eÅŸitliliÄŸi saÄŸla
        selected = []
        selected_groups = {}

        for candidate in all_candidates:
            if len(selected) >= self.MAX_CHANGES_PER_CYCLE:
                break

            group = candidate.get("group", "?")
            # AynÄ± gruptan max 2 parametre
            if selected_groups.get(group, 0) >= 2:
                continue

            selected.append(candidate)
            selected_groups[group] = selected_groups.get(group, 0) + 1

        # SeÃ§ilen adaylarÄ± DB'ye kaydet
        if selected:
            self._commit_changes(selected)
            logger.info(
                f"ğŸ¯ {len(all_candidates)} aday deÄŸiÅŸiklikten {len(selected)} seÃ§ildi "
                f"ve uygulandÄ± (max {self.MAX_CHANGES_PER_CYCLE})"
            )

        return selected

    def _log_component_analysis(self, comp_perf):
        """BileÅŸen performansÄ±nÄ± logla â€” optimizer karar gerekÃ§esi."""
        if not comp_perf:
            return

        target_wr = self.target_win_rate * 100
        logger.info("ğŸ“Š â”€â”€â”€ BileÅŸen Performans Raporu â”€â”€â”€")
        for comp, data in sorted(comp_perf.items(), key=lambda x: x[1].get("win_rate", 0)):
            wr = data.get("win_rate", 0)
            total = data.get("total", 0)
            status = "ğŸ”´" if wr < target_wr - 10 else "ğŸŸ¡" if wr < target_wr else "ğŸŸ¢"
            logger.info(f"   {status} {comp}: WR={wr:.0f}%, {total} iÅŸlem")
            if wr < target_wr - 10 and total >= 3:
                mapped = self.COMPONENT_PARAM_MAP.get(comp, [])
                if mapped:
                    logger.info(f"      â†’ Hedef parametreler: {', '.join(mapped)}")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  VERÄ° HAVUZU OLUÅTURMA
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _build_trade_pool(self):
        """
        Son kapanmÄ±ÅŸ iÅŸlemlerden analiz havuzu oluÅŸtur.

        Ã‡ekilen veriler:
          - WON/LOST ayrÄ±ÅŸtÄ±rma
          - Ort. kazanÃ§, ort. kayÄ±p, gerÃ§ek RR
          - HÄ±zlÄ± kayÄ±p oranÄ± (< 30dk)
          - BÃ¼yÃ¼k kayÄ±p oranÄ± (> %2)
          - Seans daÄŸÄ±lÄ±mÄ±
        """
        completed = get_completed_signals(200)
        winners = [s for s in completed if s["status"] == "WON"]
        losers = [s for s in completed if s["status"] == "LOST"]

        total = len(completed)

        avg_win = (
            sum(abs(s["pnl_pct"] or 0) for s in winners) / len(winners)
            if winners else 0
        )
        avg_loss = (
            sum(abs(s["pnl_pct"] or 0) for s in losers) / len(losers)
            if losers else 0
        )
        realized_rr = round(avg_win / avg_loss, 2) if avg_loss > 0 else 0

        # â”€â”€ HÄ±zlÄ± kayÄ±p analizi â”€â”€
        # Entry sonrasÄ± kÄ±sa sÃ¼rede SL â†’ fake breakout / zayÄ±f displacement
        quick_losses = 0
        for s in losers:
            duration_min = self._calc_trade_duration_min(s)
            if duration_min is not None and duration_min < 30:
                quick_losses += 1

        quick_loss_ratio = quick_losses / len(losers) if losers else 0

        # â”€â”€ BÃ¼yÃ¼k kayÄ±p analizi â”€â”€
        # SL'den Ã§ok daha bÃ¼yÃ¼k kayÄ±p = slippage veya yapÄ±sal sorun
        large_losses = sum(
            1 for s in losers
            if (s.get("pnl_pct") or 0) < -2.0
        )
        large_loss_ratio = large_losses / len(losers) if losers else 0

        # â”€â”€ Seans daÄŸÄ±lÄ±mÄ± â”€â”€
        session_stats = {}
        for s in completed:
            session = self._extract_session(s)
            if session:
                if session not in session_stats:
                    session_stats[session] = {"total": 0, "won": 0, "pnl": 0}
                session_stats[session]["total"] += 1
                if s["status"] == "WON":
                    session_stats[session]["won"] += 1
                session_stats[session]["pnl"] += (s["pnl_pct"] or 0)

        return {
            "completed": completed,
            "winners": winners,
            "losers": losers,
            "total": total,
            "win_rate": len(winners) / total * 100 if total else 0,
            "avg_win_pnl": round(avg_win, 3),
            "avg_loss_pnl": round(avg_loss, 3),
            "realized_rr": realized_rr,
            "quick_loss_ratio": round(quick_loss_ratio, 3),
            "large_loss_ratio": round(large_loss_ratio, 3),
            "session_stats": session_stats,
        }

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  HEDEF BAZLI ADIM HESAPLAMA
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _calc_adaptive_step(self, current_val, win_rate, direction="up"):
        """
        Hedef WR'ye uzaklÄ±ÄŸa gÃ¶re adaptif adÄ±m hesapla.

        WR hedefe ne kadar uzaksa adÄ±m o kadar bÃ¼yÃ¼k.
        WR hedefe yakÄ±nsa adÄ±m kÃ¼Ã§Ã¼k (ince ayar).

        direction: "up" = parametreyi artÄ±r, "down" = azalt
        """
        target = self.target_win_rate * 100  # 55%
        gap = target - win_rate  # Pozitif = hedefin altÄ±nda

        if gap <= 0:
            # Hedefin Ã¼zerinde â†’ kÃ¼Ã§Ã¼k adÄ±m (gevÅŸetme)
            intensity = 0.5
        elif gap <= 5:
            # Hedefe yakÄ±n (50-55%) â†’ normal adÄ±m
            intensity = 1.0
        elif gap <= 10:
            # Orta mesafe (45-50%) â†’ bÃ¼yÃ¼k adÄ±m
            intensity = 1.5
        else:
            # Uzak (< 45%) â†’ agresif adÄ±m
            intensity = 2.0

        step = abs(current_val) * self.learning_rate * intensity
        return step if direction == "up" else -step

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  1. DISPLACEMENT PARAMETRELERÄ° (Trigger KatmanÄ±)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _optimize_displacement(self, pool, stats, already_changed):
        """
        Displacement kalitesini WON/LOST analizinden Ã¶ÄŸren.

        v4.1 FARK: KoÅŸullar artÄ±k target_win_rate bazlÄ±.
        WR < hedef (%55) ise optimize et, uzaklÄ±ÄŸa gÃ¶re adÄ±m bÃ¼yÃ¼klÃ¼ÄŸÃ¼ ayarla.

        Kararlar:
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Durum                    â”‚ Aksiyon                          â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ WR < hedef + hÄ±zlÄ± kayÄ±pâ”‚ body_ratio â†‘  atr_mult â†‘        â”‚
        â”‚ yÃ¼ksek                   â”‚ â†’ ZayÄ±f momentum filtrelemesi    â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ WR < hedef + ort kayÄ±p  â”‚ body_ratio â†‘ size_pct â†‘          â”‚
        â”‚ yÃ¼ksek                   â”‚ â†’ Displacement boyutu yetersiz   â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ WR > hedef+10 + yeterli â”‚ body_ratio â†“  (hafif)            â”‚
        â”‚ veri                     â”‚ â†’ Daha fazla setup yakala        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        """
        changes = []

        if pool["total"] < self.min_trades:
            return changes

        avg_loss = pool["avg_loss_pnl"]
        quick_loss_ratio = pool["quick_loss_ratio"]
        win_rate = pool["win_rate"]
        target_wr = self.target_win_rate * 100  # 55

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # displacement_min_body_ratio
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        param = "displacement_min_body_ratio"
        if param not in already_changed:
            current = get_bot_param(param, ICT_PARAMS[param])

            if win_rate < target_wr and quick_loss_ratio > 0.25:
                # Hedefin altÄ±nda + hÄ±zlÄ± kayÄ±plar var â†’ displacement gÃ¶vdesi zayÄ±f
                step = self._calc_adaptive_step(current, win_rate, "up")
                new_val = current + step
                reason = (
                    f"WR ({win_rate:.1f}%) hedefin ({target_wr:.0f}%) altÄ±nda, "
                    f"hÄ±zlÄ± kayÄ±p oranÄ± {quick_loss_ratio:.0%}, "
                    f"displacement_min_body_ratio {current:.2f}'den "
                    f"{min(new_val, self.PARAM_REGISTRY[param]['bounds'][1]):.2f}'e gÃ¼ncellendi "
                    f"(daha gÃ¼Ã§lÃ¼ gÃ¶vde gerekli)"
                )
                change = self._prepare_change(param, current, new_val, reason, stats)
                if change:
                    changes.append(change)

            elif win_rate >= target_wr + 10 and pool["total"] >= 30:
                # Hedefin Ã§ok Ã¼zerinde â†’ hafif gevÅŸet
                step = self._calc_adaptive_step(current, win_rate, "up") * 0.3
                new_val = current - abs(step)
                reason = (
                    f"WR yÃ¼ksek ({win_rate:.1f}%), "
                    f"displacement_min_body_ratio {current:.2f}'den "
                    f"{max(new_val, self.PARAM_REGISTRY[param]['bounds'][0]):.2f}'e gevÅŸetildi"
                )
                change = self._prepare_change(param, current, new_val, reason, stats)
                if change:
                    changes.append(change)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # displacement_atr_multiplier
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        param = "displacement_atr_multiplier"
        if param not in already_changed:
            current = get_bot_param(param, ICT_PARAMS[param])

            if win_rate < target_wr and quick_loss_ratio > 0.20:
                # Hedefin altÄ±nda + hÄ±zlÄ± kayÄ±plar â†’ momentum yetersiz
                step = self._calc_adaptive_step(current, win_rate, "up")
                new_val = current + step
                reason = (
                    f"WR ({win_rate:.1f}%) hedefin altÄ±nda, "
                    f"hÄ±zlÄ± kayÄ±p oranÄ± {quick_loss_ratio:.0%}, "
                    f"displacement_atr_multiplier {current:.2f}'den "
                    f"{min(new_val, self.PARAM_REGISTRY[param]['bounds'][1]):.2f}'e gÃ¼ncellendi "
                    f"(daha gÃ¼Ã§lÃ¼ momentum gerekli)"
                )
                change = self._prepare_change(param, current, new_val, reason, stats)
                if change:
                    changes.append(change)

            elif win_rate >= target_wr + 10 and avg_loss < 1.0:
                # Hedefin Ã§ok Ã¼zerinde â†’ gevÅŸet
                step = self._calc_adaptive_step(current, win_rate, "up") * 0.3
                new_val = current - abs(step)
                reason = (
                    f"WR yÃ¼ksek ({win_rate:.1f}%), ort kayÄ±p dÃ¼ÅŸÃ¼k ({avg_loss:.2f}%), "
                    f"displacement_atr_multiplier {current:.2f}'den "
                    f"{max(new_val, self.PARAM_REGISTRY[param]['bounds'][0]):.2f}'e gevÅŸetildi"
                )
                change = self._prepare_change(param, current, new_val, reason, stats)
                if change:
                    changes.append(change)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # displacement_min_size_pct
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        param = "displacement_min_size_pct"
        if param not in already_changed:
            current = get_bot_param(param, ICT_PARAMS[param])

            if win_rate < target_wr and avg_loss > 1.0:
                # Hedefin altÄ±nda + kayÄ±plar bÃ¼yÃ¼k â†’ displacement boyutu yetersiz
                step = self._calc_adaptive_step(current, win_rate, "up")
                new_val = current + step
                reason = (
                    f"WR ({win_rate:.1f}%) hedefin altÄ±nda, ort kayÄ±p {avg_loss:.2f}%, "
                    f"displacement_min_size_pct {current:.4f}'den "
                    f"{min(new_val, self.PARAM_REGISTRY[param]['bounds'][1]):.4f}'e gÃ¼ncellendi"
                )
                change = self._prepare_change(param, current, new_val, reason, stats)
                if change:
                    changes.append(change)

            elif win_rate >= target_wr + 10 and pool["total"] >= 25:
                step = self._calc_adaptive_step(current, win_rate, "up") * 0.3
                new_val = current - abs(step)
                reason = (
                    f"WR iyi ({win_rate:.1f}%), "
                    f"displacement_min_size_pct {current:.4f}'den "
                    f"{max(new_val, self.PARAM_REGISTRY[param]['bounds'][0]):.4f}'e gevÅŸetildi"
                )
                change = self._prepare_change(param, current, new_val, reason, stats)
                if change:
                    changes.append(change)

        return changes

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  2. FVG PARAMETRELERÄ° (POI KatmanÄ±)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _optimize_fvg(self, pool, stats, already_changed):
        """
        FVG kalitesini WON/LOST analizinden Ã¶ÄŸren.

        v4.1 FARK: target_win_rate bazlÄ± koÅŸullar.

        Kararlar:
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Durum                    â”‚ Aksiyon                          â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ WR < hedef               â”‚ fvg_min_size_pct â†‘               â”‚
        â”‚                          â”‚ â†’ KÃ¼Ã§Ã¼k FVG'leri ele             â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ WR < hedef               â”‚ fvg_max_age_candles â†“            â”‚
        â”‚                          â”‚ â†’ Eski FVG'ler gÃ¼venilmez        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ WR > hedef+10            â”‚ fvg_min_size_pct â†“ (hafif)       â”‚
        â”‚                          â”‚ â†’ Daha fazla FVG yakala          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        """
        changes = []

        if pool["total"] < self.min_trades:
            return changes

        realized_rr = pool["realized_rr"]
        win_rate = pool["win_rate"]
        target_wr = self.target_win_rate * 100

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # fvg_min_size_pct
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        param = "fvg_min_size_pct"
        if param not in already_changed:
            current = get_bot_param(param, ICT_PARAMS[param])

            if win_rate < target_wr:
                # Hedefin altÄ±nda â†’ kÃ¼Ã§Ã¼k FVG'leri filtrele
                step = self._calc_adaptive_step(current, win_rate, "up")
                new_val = current + step
                reason = (
                    f"WR ({win_rate:.1f}%) hedefin ({target_wr:.0f}%) altÄ±nda, "
                    f"fvg_min_size_pct {current:.5f}'den "
                    f"{min(new_val, self.PARAM_REGISTRY[param]['bounds'][1]):.5f}'e gÃ¼ncellendi "
                    f"(daha bÃ¼yÃ¼k FVG hedefleme)"
                )
                change = self._prepare_change(param, current, new_val, reason, stats)
                if change:
                    changes.append(change)

            elif win_rate >= target_wr + 10 and realized_rr > 2.0:
                # Hedefin Ã§ok Ã¼zerinde + RR iyi â†’ gevÅŸet
                step = self._calc_adaptive_step(current, win_rate, "up") * 0.3
                new_val = current - abs(step)
                reason = (
                    f"WR iyi ({win_rate:.1f}%) ve RR iyi ({realized_rr:.2f}), "
                    f"fvg_min_size_pct {current:.5f}'den "
                    f"{max(new_val, self.PARAM_REGISTRY[param]['bounds'][0]):.5f}'e gevÅŸetildi"
                )
                change = self._prepare_change(param, current, new_val, reason, stats)
                if change:
                    changes.append(change)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # fvg_max_age_candles
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        param = "fvg_max_age_candles"
        if param not in already_changed:
            current = get_bot_param(param, ICT_PARAMS[param])

            if win_rate < target_wr and pool["total"] >= 20:
                # Hedefin altÄ±nda â†’ eski FVG'leri kÄ±sÄ±tla
                step = max(1, self._calc_adaptive_step(current, win_rate, "up") * 0.5)
                new_val = current - abs(step)
                reason = (
                    f"WR ({win_rate:.1f}%) hedefin altÄ±nda, "
                    f"fvg_max_age_candles {int(current)}'den "
                    f"{max(int(new_val), self.PARAM_REGISTRY[param]['bounds'][0])}'e azaltÄ±ldÄ± "
                    f"(daha taze FVG hedefleme)"
                )
                change = self._prepare_change(param, current, new_val, reason, stats)
                if change:
                    changes.append(change)

            elif win_rate >= target_wr + 10:
                # Hedefin Ã¼zerinde â†’ eski FVG'leri de dahil et
                step = max(1, abs(current * self.learning_rate * 0.3))
                new_val = current + step
                reason = (
                    f"WR yÃ¼ksek ({win_rate:.1f}%), "
                    f"fvg_max_age_candles {int(current)}'den "
                    f"{min(int(new_val), self.PARAM_REGISTRY[param]['bounds'][1])}'e geniÅŸletildi"
                )
                change = self._prepare_change(param, current, new_val, reason, stats)
                if change:
                    changes.append(change)

        return changes

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  3. LÄ°KÄ°DÄ°TE PARAMETRELERÄ° (POI KatmanÄ±)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _optimize_liquidity(self, pool, stats, already_changed):
        """
        Likidite sweep kalitesini analiz et.

        v4.1 FARK: target_win_rate bazlÄ± koÅŸullar.

        Kararlar:
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Durum                    â”‚ Aksiyon                          â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ WR < hedef + hÄ±zlÄ± kayÄ±p â”‚ tolerance â†“                      â”‚
        â”‚                          â”‚ â†’ Sahte sweep'leri ele           â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ WR > hedef+10            â”‚ tolerance â†‘ (hafif)              â”‚
        â”‚                          â”‚ â†’ Daha fazla seviye yakala       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        """
        changes = []

        if pool["total"] < self.min_trades:
            return changes

        quick_loss_ratio = pool["quick_loss_ratio"]
        win_rate = pool["win_rate"]
        target_wr = self.target_win_rate * 100

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # liquidity_equal_tolerance
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        param = "liquidity_equal_tolerance"
        if param not in already_changed:
            current = get_bot_param(param, ICT_PARAMS[param])

            if win_rate < target_wr and quick_loss_ratio > 0.20:
                # Hedefin altÄ±nda + hÄ±zlÄ± kayÄ±plar â†’ sahte sweep'ler
                step = self._calc_adaptive_step(current, win_rate, "up")
                new_val = current - abs(step)  # Tolerans kÃ¼Ã§Ã¼lt = daha hassas
                reason = (
                    f"WR ({win_rate:.1f}%) hedefin altÄ±nda, "
                    f"hÄ±zlÄ± kayÄ±p oranÄ± {quick_loss_ratio:.0%}, "
                    f"liquidity_equal_tolerance {current:.5f}'den "
                    f"{max(new_val, self.PARAM_REGISTRY[param]['bounds'][0]):.5f}'e "
                    f"sÄ±kÄ±laÅŸtÄ±rÄ±ldÄ± (sahte sweep filtresi)"
                )
                change = self._prepare_change(param, current, new_val, reason, stats)
                if change:
                    changes.append(change)

            elif win_rate >= target_wr + 10 and quick_loss_ratio < 0.15:
                # Hedefin Ã§ok Ã¼zerinde â†’ hafif gevÅŸet
                step = self._calc_adaptive_step(current, win_rate, "up") * 0.3
                new_val = current + abs(step)
                reason = (
                    f"WR yÃ¼ksek ({win_rate:.1f}%), hÄ±zlÄ± kayÄ±p dÃ¼ÅŸÃ¼k ({quick_loss_ratio:.0%}), "
                    f"liquidity_equal_tolerance {current:.5f}'den "
                    f"{min(new_val, self.PARAM_REGISTRY[param]['bounds'][1]):.5f}'e "
                    f"gevÅŸetildi (daha fazla seviye)"
                )
                change = self._prepare_change(param, current, new_val, reason, stats)
                if change:
                    changes.append(change)

        return changes

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  4. YAPISAL PARAMETRELER (OB, Swing)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _optimize_structural(self, pool, stats, already_changed):
        """
        Order Block ve swing noktasÄ± parametrelerini optimize et.

        v4.1 FARK: target_win_rate bazlÄ± koÅŸullar.

        Kararlar:
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Durum                    â”‚ Aksiyon                          â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ WR < hedef               â”‚ ob_body â†‘, ob_age â†“, swing â†‘    â”‚
        â”‚                          â”‚ â†’ Daha kaliteli yapÄ±sal veri     â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ WR > hedef+10            â”‚ ob_body â†“ (hafif)                â”‚
        â”‚                          â”‚ â†’ Daha fazla yapÄ± belirlensin    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        """
        changes = []

        if pool["total"] < self.min_trades:
            return changes

        win_rate = pool["win_rate"]
        avg_loss = pool["avg_loss_pnl"]
        target_wr = self.target_win_rate * 100

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ob_body_ratio_min
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        param = "ob_body_ratio_min"
        if param not in already_changed:
            current = get_bot_param(param, ICT_PARAMS[param])

            if win_rate < target_wr and pool["total"] >= 20:
                step = self._calc_adaptive_step(current, win_rate, "up")
                new_val = current + step
                reason = (
                    f"WR ({win_rate:.1f}%) hedefin ({target_wr:.0f}%) altÄ±nda, "
                    f"ob_body_ratio_min {current:.2f}'den "
                    f"{min(new_val, self.PARAM_REGISTRY[param]['bounds'][1]):.2f}'e gÃ¼ncellendi "
                    f"(OB kalite filtresi sÄ±kÄ±laÅŸtÄ±rÄ±ldÄ±)"
                )
                change = self._prepare_change(param, current, new_val, reason, stats)
                if change:
                    changes.append(change)

            elif win_rate >= target_wr + 10 and pool["total"] >= 20:
                step = self._calc_adaptive_step(current, win_rate, "up") * 0.3
                new_val = current - abs(step)
                reason = (
                    f"WR yÃ¼ksek ({win_rate:.1f}%), "
                    f"ob_body_ratio_min {current:.2f}'den "
                    f"{max(new_val, self.PARAM_REGISTRY[param]['bounds'][0]):.2f}'e gevÅŸetildi"
                )
                change = self._prepare_change(param, current, new_val, reason, stats)
                if change:
                    changes.append(change)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ob_max_age_candles
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        param = "ob_max_age_candles"
        if param not in already_changed:
            current = get_bot_param(param, ICT_PARAMS[param])

            if win_rate < target_wr and avg_loss > 0.8:
                # Hedefin altÄ±nda â†’ eski OB'leri kÄ±sÄ±tla
                step = max(1, self._calc_adaptive_step(current, win_rate, "up") * 0.3)
                new_val = current - abs(step)
                reason = (
                    f"WR ({win_rate:.1f}%) hedefin altÄ±nda, ort kayÄ±p {avg_loss:.2f}%, "
                    f"ob_max_age_candles {int(current)}'den "
                    f"{max(int(new_val), self.PARAM_REGISTRY[param]['bounds'][0])}'e "
                    f"azaltÄ±ldÄ± (daha taze OB hedefleme)"
                )
                change = self._prepare_change(param, current, new_val, reason, stats)
                if change:
                    changes.append(change)

            elif win_rate >= target_wr + 10:
                # Hedefin Ã§ok Ã¼zerinde â†’ gevÅŸet
                step = max(1, abs(current * self.learning_rate * 0.3))
                new_val = current + step
                reason = (
                    f"WR yÃ¼ksek ({win_rate:.1f}%), "
                    f"ob_max_age_candles {int(current)}'den "
                    f"{min(int(new_val), self.PARAM_REGISTRY[param]['bounds'][1])}'e geniÅŸletildi"
                )
                change = self._prepare_change(param, current, new_val, reason, stats)
                if change:
                    changes.append(change)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # swing_lookback
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        param = "swing_lookback"
        if param not in already_changed:
            current = get_bot_param(param, ICT_PARAMS[param])

            if win_rate < target_wr and pool["quick_loss_ratio"] > 0.25:
                # Hedefin altÄ±nda + hÄ±zlÄ± kayÄ±plar â†’ swing seviyeleri hassas
                new_val = current + 1
                reason = (
                    f"WR ({win_rate:.1f}%) hedefin altÄ±nda, "
                    f"hÄ±zlÄ± kayÄ±p oranÄ± {pool['quick_loss_ratio']:.0%}, "
                    f"swing_lookback {int(current)}'den {int(new_val)}'e artÄ±rÄ±ldÄ± "
                    f"(daha gÃ¼venilir swing seviyeleri)"
                )
                change = self._prepare_change(param, current, new_val, reason, stats)
                if change:
                    changes.append(change)

            elif win_rate >= target_wr + 10 and current > 4:
                # Hedefin Ã§ok Ã¼zerinde + lookback bÃ¼yÃ¼k â†’ gevÅŸet
                new_val = current - 1
                reason = (
                    f"WR yÃ¼ksek ({win_rate:.1f}%), "
                    f"swing_lookback {int(current)}'den {int(new_val)}'e azaltÄ±ldÄ± "
                    f"(daha fazla swing noktasÄ±)"
                )
                change = self._prepare_change(param, current, new_val, reason, stats)
                if change:
                    changes.append(change)

        return changes

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  5. RÄ°SK PARAMETRELERÄ° (SL, TP)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _optimize_risk(self, pool, stats, already_changed):
        """
        SL ve min RR parametrelerini gerÃ§ekleÅŸen trade sonuÃ§larÄ±ndan Ã¶ÄŸren.

        v4.1 FARK: target_win_rate bazlÄ± koÅŸullar.

        Kararlar:
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Durum                    â”‚ Aksiyon                         â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ WR < hedef + kayÄ±p       â”‚ default_sl_pct â†‘                â”‚
        â”‚ ort SL'den kÃ¼Ã§Ã¼k         â”‚ â†’ Noise SL tetikliyor           â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ WR < hedef + kayÄ±p bÃ¼yÃ¼k â”‚ default_sl_pct â†“                â”‚
        â”‚                          â”‚ â†’ SL Ã§ok geniÅŸ                  â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ WR < hedef + RR dÃ¼ÅŸÃ¼k    â”‚ min_rr_ratio â†‘                  â”‚
        â”‚                          â”‚ â†’ Kalite filtresi sÄ±kÄ±laÅŸtÄ±r    â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ WR > hedef + RR dÃ¼ÅŸÃ¼k    â”‚ min_rr_ratio â†“                  â”‚
        â”‚                          â”‚ â†’ Daha fazla setup yakala       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        """
        changes = []

        if pool["total"] < self.min_trades:
            return changes

        avg_win = pool["avg_win_pnl"]
        avg_loss = pool["avg_loss_pnl"]
        win_rate = pool["win_rate"]
        realized_rr = pool["realized_rr"]
        target_wr = self.target_win_rate * 100

        if avg_win <= 0 or avg_loss <= 0:
            return changes

        loss_rate = len(pool["losers"]) / pool["total"] if pool["total"] else 0

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # default_sl_pct
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        param = "default_sl_pct"
        if param not in already_changed:
            current = get_bot_param(param, ICT_PARAMS[param])
            sl_as_pct = current * 100  # 0.012 â†’ 1.2%

            if win_rate < target_wr and avg_loss < sl_as_pct * 0.8:
                # Hedefin altÄ±nda + kayÄ±plar SL'den kÃ¼Ã§Ã¼k â†’ noise tetikliyor
                step = self._calc_adaptive_step(current, win_rate, "up")
                new_val = current + step
                reason = (
                    f"WR ({win_rate:.1f}%) hedefin altÄ±nda, "
                    f"ort kayÄ±p ({avg_loss:.2f}%) SL'den kÃ¼Ã§Ã¼k â†’ noise korumasÄ±, "
                    f"default_sl_pct {current:.4f}'den "
                    f"{min(new_val, self.PARAM_REGISTRY[param]['bounds'][1]):.4f}'e geniÅŸletildi"
                )
                change = self._prepare_change(param, current, new_val, reason, stats)
                if change:
                    changes.append(change)

            elif win_rate < target_wr and avg_loss > sl_as_pct * 1.2:
                # Hedefin altÄ±nda + kayÄ±plar SL'den bÃ¼yÃ¼k â†’ SL Ã§ok geniÅŸ
                step = self._calc_adaptive_step(current, win_rate, "up")
                new_val = current - abs(step)
                reason = (
                    f"WR ({win_rate:.1f}%) hedefin altÄ±nda, "
                    f"ort kayÄ±p ({avg_loss:.2f}%) SL'den bÃ¼yÃ¼k â†’ SL daraltÄ±lÄ±yor, "
                    f"default_sl_pct {current:.4f}'den "
                    f"{max(new_val, self.PARAM_REGISTRY[param]['bounds'][0]):.4f}'e daraltÄ±ldÄ±"
                )
                change = self._prepare_change(param, current, new_val, reason, stats)
                if change:
                    changes.append(change)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # min_rr_ratio
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        param = "min_rr_ratio"
        if param not in already_changed:
            current = get_bot_param(param, ICT_PARAMS[param])

            if win_rate >= target_wr and realized_rr < 1.3:
                # Hedefin Ã¼zerinde ama RR dÃ¼ÅŸÃ¼k â†’ daha fazla setup yakala
                new_val = current - 0.1
                reason = (
                    f"WR iyi ({win_rate:.1f}%) ama RR dÃ¼ÅŸÃ¼k ({realized_rr:.2f}), "
                    f"min_rr_ratio {current:.2f}'den "
                    f"{max(new_val, self.PARAM_REGISTRY[param]['bounds'][0]):.2f}'e "
                    f"gevÅŸetildi (daha fazla setup)"
                )
                change = self._prepare_change(param, current, new_val, reason, stats)
                if change:
                    changes.append(change)

            elif win_rate < target_wr:
                # Hedefin altÄ±nda â†’ RR eÅŸiÄŸini artÄ±r (sadece yÃ¼ksek RR setuplara gir)
                step = 0.05 + (target_wr - win_rate) / 100  # WR uzaksa daha bÃ¼yÃ¼k adÄ±m
                new_val = current + step
                reason = (
                    f"WR ({win_rate:.1f}%) hedefin ({target_wr:.0f}%) altÄ±nda, "
                    f"min_rr_ratio {current:.2f}'den "
                    f"{min(new_val, self.PARAM_REGISTRY[param]['bounds'][1]):.2f}'e "
                    f"artÄ±rÄ±ldÄ± (sadece yÃ¼ksek RR setuplara gir)"
                )
                change = self._prepare_change(param, current, new_val, reason, stats)
                if change:
                    changes.append(change)

        return changes

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  6. POI CONFLUENCE PARAMETRELERÄ°
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _optimize_poi_confluence(self, pool, stats, already_changed):
        """
        POI bÃ¶lgesi ile fiyat arasÄ±ndaki mesafe eÅŸiÄŸini optimize et.

        v4.1 FARK: target_win_rate bazlÄ± koÅŸullar.

        Kararlar:
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Durum                    â”‚ Aksiyon                         â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ WR < hedef + hÄ±zlÄ± kayÄ±p â”‚ poi_max_distance_pct â†“          â”‚
        â”‚                          â”‚ â†’ POI'ye daha yakÄ±n giriÅŸ       â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ WR > hedef+10            â”‚ poi_max_distance_pct â†‘ (hafif)  â”‚
        â”‚                          â”‚ â†’ Daha fazla setup yakala       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        """
        changes = []

        if pool["total"] < self.min_trades:
            return changes

        win_rate = pool["win_rate"]
        quick_loss_ratio = pool["quick_loss_ratio"]
        realized_rr = pool["realized_rr"]
        target_wr = self.target_win_rate * 100

        param = "poi_max_distance_pct"
        if param not in already_changed:
            current = get_bot_param(param, ICT_PARAMS[param])

            if win_rate < target_wr and quick_loss_ratio > 0.20:
                # Hedefin altÄ±nda + hÄ±zlÄ± kayÄ±plar â†’ POI'ye daha yakÄ±n gir
                step = self._calc_adaptive_step(current, win_rate, "up")
                new_val = current - abs(step)
                reason = (
                    f"WR ({win_rate:.1f}%) hedefin altÄ±nda, "
                    f"hÄ±zlÄ± kayÄ±p oranÄ± {quick_loss_ratio:.0%}, "
                    f"poi_max_distance_pct {current:.4f}'den "
                    f"{max(new_val, self.PARAM_REGISTRY[param]['bounds'][0]):.4f}'e "
                    f"daraltÄ±ldÄ± (POI'ye daha yakÄ±n giriÅŸ)"
                )
                change = self._prepare_change(param, current, new_val, reason, stats)
                if change:
                    changes.append(change)

            elif win_rate >= target_wr + 10 and realized_rr > 1.5:
                # Hedefin Ã§ok Ã¼zerinde â†’ hafif geniÅŸlet
                step = self._calc_adaptive_step(current, win_rate, "up") * 0.3
                new_val = current + abs(step)
                reason = (
                    f"WR yÃ¼ksek ({win_rate:.1f}%), RR iyi ({realized_rr:.2f}), "
                    f"poi_max_distance_pct {current:.4f}'den "
                    f"{min(new_val, self.PARAM_REGISTRY[param]['bounds'][1]):.4f}'e "
                    f"gevÅŸetildi (daha fazla setup)"
                )
                change = self._prepare_change(param, current, new_val, reason, stats)
                if change:
                    changes.append(change)

        return changes

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  7. NARRATIVE PARAMETRELERÄ° (BOS Hassasiyeti)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _optimize_narrative(self, pool, stats, already_changed):
        """
        BOS (Break of Structure) kÄ±rÄ±lÄ±m hassasiyetini optimize et.

        v4.1 FARK: target_win_rate bazlÄ± koÅŸullar.

        Kararlar:
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Durum                    â”‚ Aksiyon                         â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ WR < hedef               â”‚ bos_min_displacement â†‘          â”‚
        â”‚                          â”‚ â†’ Sahte BOS'larÄ± filtrele       â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ WR > hedef+10            â”‚ bos_min_displacement â†“ (hafif)  â”‚
        â”‚                          â”‚ â†’ Daha fazla narrative yakala   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        """
        changes = []

        if pool["total"] < self.min_trades:
            return changes

        win_rate = pool["win_rate"]
        quick_loss_ratio = pool["quick_loss_ratio"]
        avg_loss = pool["avg_loss_pnl"]
        target_wr = self.target_win_rate * 100

        param = "bos_min_displacement"
        if param not in already_changed:
            current = get_bot_param(param, ICT_PARAMS[param])

            if win_rate < target_wr:
                # Hedefin altÄ±nda â†’ BOS hassasiyetini artÄ±r
                step = self._calc_adaptive_step(current, win_rate, "up")
                new_val = current + step
                reason = (
                    f"WR ({win_rate:.1f}%) hedefin ({target_wr:.0f}%) altÄ±nda, "
                    f"bos_min_displacement {current:.4f}'den "
                    f"{min(new_val, self.PARAM_REGISTRY[param]['bounds'][1]):.4f}'e "
                    f"artÄ±rÄ±ldÄ± (daha gÃ¼Ã§lÃ¼ BOS gerekli)"
                )
                change = self._prepare_change(param, current, new_val, reason, stats)
                if change:
                    changes.append(change)

            elif win_rate >= target_wr + 10 and pool["total"] < 30:
                # Hedefin Ã§ok Ã¼zerinde ama az iÅŸlem â†’ gevÅŸet
                step = self._calc_adaptive_step(current, win_rate, "up") * 0.3
                new_val = current - abs(step)
                reason = (
                    f"WR yÃ¼ksek ({win_rate:.1f}%) ama az iÅŸlem ({pool['total']}), "
                    f"bos_min_displacement {current:.4f}'den "
                    f"{max(new_val, self.PARAM_REGISTRY[param]['bounds'][0]):.4f}'e "
                    f"gevÅŸetildi (daha fazla narrative)"
                )
                change = self._prepare_change(param, current, new_val, reason, stats)
                if change:
                    changes.append(change)

        return changes

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  ACÄ°L MOD
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _emergency_mode(self, pool, stats):
        """
        ğŸš¨ ACÄ°L MOD â€” %0 win rate ile ardÄ±ÅŸÄ±k kayÄ±plarda tetiklenir.

        Agresif sÄ±kÄ±laÅŸtÄ±rma: displacement ve FVG eÅŸiklerini yÃ¼kselt
        â†’ sadece en kaliteli setup'lara gir.

        Tetikleme: WR == 0% ve >= 3 kayÄ±p (max 10 kayÄ±p sonrasÄ± pasif)
        """
        changes = []
        n_losses = len(pool["losers"])

        if n_losses > 10:
            logger.info("ğŸš¨ Acil mod atlandÄ± â€” yeterli veri toplandÄ±")
            return changes

        logger.warning(
            f"ğŸš¨ ACÄ°L MOD AKTÄ°F: %0 win rate, {n_losses} ardÄ±ÅŸÄ±k kayÄ±p â†’ "
            f"Displacement ve FVG filtreleri agresif sÄ±kÄ±laÅŸtÄ±rÄ±lÄ±yor!"
        )

        # 1. Displacement body ratio sÄ±kÄ±laÅŸtÄ±r
        param = "displacement_min_body_ratio"
        current = get_bot_param(param, ICT_PARAMS[param])
        new_val = current * 1.08  # %8 artÄ±ÅŸ
        reason = (
            f"ğŸš¨ ACÄ°L: {n_losses} ardÄ±ÅŸÄ±k kayÄ±p tespit edildi, "
            f"displacement_min_body_ratio {current:.2f}'den {new_val:.2f}'e sÄ±kÄ±laÅŸtÄ±rÄ±ldÄ±"
        )
        change = self._apply_change(param, current, new_val, reason, stats)
        if change:
            changes.append(change)

        # 2. FVG minimum boyut sÄ±kÄ±laÅŸtÄ±r
        param = "fvg_min_size_pct"
        current = get_bot_param(param, ICT_PARAMS[param])
        new_val = current * 1.10  # %10 artÄ±ÅŸ
        reason = (
            f"ğŸš¨ ACÄ°L: KÃ¼Ã§Ã¼k FVG'lerden girilen kayÄ±plar â†’ "
            f"fvg_min_size_pct {current:.5f}'den {new_val:.5f}'e yÃ¼kseltildi"
        )
        change = self._apply_change(param, current, new_val, reason, stats)
        if change:
            changes.append(change)

        # 3. SL hafif geniÅŸlet (premature stop-out korumasÄ±)
        param = "default_sl_pct"
        current = get_bot_param(param, ICT_PARAMS[param])
        if current < 0.020:
            new_val = current * 1.06  # %6 artÄ±ÅŸ
            reason = (
                f"ğŸš¨ ACÄ°L: SL mesafesi {current:.4f}'den {new_val:.4f}'e "
                f"geniÅŸletildi (erken stop-out korumasÄ±)"
            )
            change = self._apply_change(param, current, new_val, reason, stats)
            if change:
                changes.append(change)

        return changes

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  BÄ°LGÄ° ANALÄ°ZLERÄ° (parametre deÄŸiÅŸtirmez, sadece loglar)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _log_session_analysis(self, pool):
        """
        Seans bazlÄ± (London Open / NY Open) performans analizi.

        Trade notlarÄ±ndaki Session bilgisini parse ederek hangi killzone'un
        daha baÅŸarÄ±lÄ± olduÄŸunu raporlar. Parametre deÄŸiÅŸtirmez.
        """
        session_stats = pool.get("session_stats", {})
        if not session_stats:
            return

        logger.info("ğŸ“Š â”€â”€â”€ Seans Performans Raporu â”€â”€â”€")
        for session, data in session_stats.items():
            wr = data["won"] / data["total"] * 100 if data["total"] else 0
            avg_pnl = data["pnl"] / data["total"] if data["total"] else 0
            logger.info(
                f"   {session}: {data['total']} iÅŸlem, "
                f"WR={wr:.0f}%, ort PnL={avg_pnl:+.2f}%"
            )
            if data["total"] >= 5 and wr < 35:
                logger.warning(
                    f"   âš ï¸ {session} dÃ¼ÅŸÃ¼k performans gÃ¶steriyor â€” "
                    f"bu killzone'da dikkatli ol"
                )

    def _log_htf_bias_analysis(self):
        """
        HTF Bias (4H yÃ¶n tayini) doÄŸruluk analizi.

        BULLISH vs BEARISH bias'Ä±n hangi yÃ¶nde daha isabetli olduÄŸunu raporlar.
        Parametre deÄŸiÅŸtirmez.
        """
        accuracy = get_htf_bias_accuracy()
        if not accuracy:
            return

        logger.info("ğŸ“Š â”€â”€â”€ HTF Bias DoÄŸruluk Raporu â”€â”€â”€")
        for bias, data in accuracy.items():
            logger.info(
                f"   HTF '{bias}': {data['total']} iÅŸlem, WR={data['win_rate']}%"
            )
            if data["total"] >= 5 and data["win_rate"] < 40:
                logger.warning(
                    f"   âš ï¸ HTF '{bias}' dÃ¼ÅŸÃ¼k doÄŸruluk ({data['win_rate']}%) â€” "
                    f"bu bias ile dikkatli ol"
                )

    def _log_entry_mode_analysis(self):
        """
        v4.0: MARKET-only â€” entry mode karÅŸÄ±laÅŸtÄ±rmasÄ± artÄ±k geÃ§ersiz.
        Geriye uyumluluk iÃ§in boÅŸ bÄ±rakÄ±ldÄ±, Ã§aÄŸrÄ±lmaz.
        """
        pass

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  YARDIMCI METODLAR
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _prepare_change(self, param_name, current_val, new_val, reason, stats):
        """
        Parametre deÄŸiÅŸikliÄŸini HESAPLA ama KAYDETME (aday oluÅŸtur).

        Kontroller:
          1. Max deÄŸiÅŸim limiti (%10)
          2. SÄ±nÄ±r kontrolÃ¼ (bounds clamp)
          3. Integer/float uyumu
          4. Minimum anlamlÄ± deÄŸiÅŸiklik (%1)

        Returns:
            dict: Aday deÄŸiÅŸiklik bilgisi veya None (geÃ§ersizse)
        """
        registry = self.PARAM_REGISTRY.get(param_name)
        if not registry:
            logger.warning(f"âš ï¸ {param_name} parametre rejistrisinde bulunamadÄ±")
            return None

        min_b, max_b = registry["bounds"]

        # â”€â”€ Max deÄŸiÅŸim limiti (%10) â”€â”€
        max_change = abs(current_val * self.max_change_pct)
        if max_change > 0 and abs(new_val - current_val) > max_change:
            new_val = current_val + (
                max_change if new_val > current_val else -max_change
            )

        # â”€â”€ SÄ±nÄ±r kontrolÃ¼ â”€â”€
        new_val = max(min_b, min(max_b, new_val))

        # â”€â”€ Integer parametre kontrolÃ¼ â”€â”€
        if isinstance(ICT_PARAMS.get(param_name), int):
            new_val = int(round(new_val))
        else:
            # KÃ¼Ã§Ã¼k deÄŸerler iÃ§in daha fazla ondalÄ±k
            if abs(new_val) < 0.01:
                new_val = round(new_val, 6)
            elif abs(new_val) < 1:
                new_val = round(new_val, 5)
            else:
                new_val = round(new_val, 4)

        # â”€â”€ AnlamlÄ± deÄŸiÅŸiklik kontrolÃ¼ (%1'den az â†’ atla) â”€â”€
        if current_val != 0:
            change_pct = abs(new_val - current_val) / abs(current_val)
            if change_pct < 0.01:
                return None
        elif new_val == current_val:
            return None

        return {
            "param": param_name,
            "old": current_val,
            "new": new_val,
            "reason": reason,
            "bounds": [min_b, max_b],
            "group": registry["group"],
            "_stats": stats,  # commit sÄ±rasÄ±nda lazÄ±m olacak
        }

    def _commit_changes(self, candidates, stats=None):
        """
        SeÃ§ilmiÅŸ aday deÄŸiÅŸiklikleri DB'ye kaydet.

        Args:
            candidates: _prepare_change'den dÃ¶nen aday listesi
            stats: Performans istatistikleri (yoksa adaydan alÄ±nÄ±r)
        """
        for c in candidates:
            s = stats or c.get("_stats", {})
            default_val = ICT_PARAMS.get(c["param"], c["old"])
            save_bot_param(c["param"], c["new"], default_val)
            add_optimization_log(
                c["param"], c["old"], c["new"], c["reason"],
                s.get("win_rate", 0), s.get("win_rate", 0),
                s.get("total_trades", 0),
            )
            logger.info(f"ğŸ“Š {c['param']}: {c['old']} â†’ {c['new']} | {c['reason']}")
            # Temizlik: iÃ§ alanÄ± kaldÄ±r
            c.pop("_stats", None)

    def _apply_change(self, param_name, current_val, new_val, reason, stats):
        """
        Parametre deÄŸiÅŸikliÄŸini HEMEN uygula (acil mod / rollback iÃ§in).

        prepare + commit'i tek Ã§aÄŸrÄ±da yapar.
        Returns:
            dict: DeÄŸiÅŸiklik bilgisi veya None
        """
        candidate = self._prepare_change(param_name, current_val, new_val, reason, stats)
        if candidate:
            self._commit_changes([candidate], stats)
        return candidate

    def _get_last_change_direction(self, param_name):
        """
        Son optimizasyon loglarÄ±ndan parametrenin son deÄŸiÅŸim yÃ¶nÃ¼nÃ¼ tespit et.

        Returns: "up" (artÄ±rÄ±ldÄ±), "down" (azaltÄ±ldÄ±), "none" (deÄŸiÅŸmedi)
        """
        try:
            logs = get_optimization_logs(30)
            for log in logs:
                if log.get("param_name") == param_name:
                    old_val = float(log.get("old_value", 0))
                    new_val = float(log.get("new_value", 0))
                    if new_val > old_val:
                        return "up"
                    elif new_val < old_val:
                        return "down"
                    return "none"
        except Exception:
            pass
        return "none"

    def _calc_trade_duration_min(self, signal):
        """
        Bir iÅŸlemin sÃ¼resini dakika cinsinden hesapla.

        entry_time ile close_time arasÄ±ndaki farkÄ± dÃ¶ndÃ¼rÃ¼r.
        Veri yoksa veya parse hatalÄ±ysa None dÃ¶ner.
        """
        entry_time = signal.get("entry_time") or signal.get("created_at", "")
        close_time = signal.get("close_time", "")

        if not entry_time or not close_time:
            return None

        try:
            entry_dt = datetime.fromisoformat(entry_time)
            close_dt = datetime.fromisoformat(close_time)
            duration_min = (close_dt - entry_dt).total_seconds() / 60
            return round(duration_min, 1)
        except Exception:
            return None

    def _extract_session(self, signal):
        """
        Sinyal notlarÄ±ndan seans bilgisini Ã§Ä±kar.

        Notes formatÄ±: "... | Session: NY_OPEN | ..."
        Returns: "LONDON_OPEN", "NY_OPEN", vb. veya None
        """
        notes = signal.get("notes", "") or ""
        if "Session:" not in notes:
            return None

        try:
            session_part = notes.split("Session:")[1].split("|")[0].strip()
            return session_part if session_part else None
        except Exception:
            return None

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  OPTÄ°MÄ°ZASYON Ã–ZETÄ° (API Endpoint)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def get_optimization_summary(self):
        """
        Optimizasyon Ã¶zetini dÃ¶ndÃ¼r â€” app.py API endpoint'i iÃ§in.

        Endpoint: GET /api/optimization/summary

        Geriye uyumlu alanlar korundu + v4.0 alanlarÄ± eklendi:
        - optimizer_version, param_groups, realized_rr
        - changed_params artÄ±k bounds ve group bilgisi iÃ§erir
        """
        stats = get_performance_summary()
        all_params = get_all_bot_params()
        loss_info = get_loss_analysis(30)
        htf_accuracy = get_htf_bias_accuracy()

        # â”€â”€ VarsayÄ±landan deÄŸiÅŸen parametreleri bul â”€â”€
        changed_params = {}
        for param_name, registry in self.PARAM_REGISTRY.items():
            default_val = ICT_PARAMS.get(param_name)
            if default_val is None:
                continue

            current_val = all_params.get(param_name, default_val)
            try:
                current_val = float(current_val)
                default_val = float(default_val)
            except (TypeError, ValueError):
                continue

            if abs(current_val - default_val) > 0.0001:
                change_pct = (
                    ((current_val - default_val) / default_val) * 100
                    if default_val != 0 else 0
                )
                changed_params[param_name] = {
                    "default": default_val,
                    "current": current_val,
                    "change_pct": round(change_pct, 1),
                    "bounds": list(registry["bounds"]),
                    "group": registry["group"],
                    "description": registry["desc"],
                }

        # â”€â”€ WON/LOST analiz Ã¶zeti â”€â”€
        completed = get_completed_signals(100)
        winners = [s for s in completed if s["status"] == "WON"]
        losers = [s for s in completed if s["status"] == "LOST"]

        avg_win = (
            sum(abs(s["pnl_pct"] or 0) for s in winners) / len(winners)
            if winners else 0
        )
        avg_loss = (
            sum(abs(s["pnl_pct"] or 0) for s in losers) / len(losers)
            if losers else 0
        )
        realized_rr = round(avg_win / avg_loss, 2) if avg_loss > 0 else 0

        # â”€â”€ HÄ±zlÄ± kayÄ±p analizi â”€â”€
        quick_losses = 0
        for s in losers:
            dur = self._calc_trade_duration_min(s)
            if dur is not None and dur < 30:
                quick_losses += 1
        quick_loss_ratio = (
            round(quick_losses / len(losers) * 100, 1) if losers else 0
        )

        return {
            "optimizer_version": "4.1 â€” Target-Based Adaptive Optimizer (Narrative â†’ POI â†’ Trigger)",
            "total_optimizations": len(changed_params),
            "current_win_rate": stats["win_rate"],
            "target_win_rate": self.target_win_rate * 100,
            "realized_rr": realized_rr,
            "avg_win_pnl": round(avg_win, 2),
            "avg_loss_pnl": round(avg_loss, 2),
            "quick_loss_ratio_pct": quick_loss_ratio,
            "changed_params": changed_params,
            "performance": stats,
            "loss_lessons": loss_info.get("lesson_summary", []),
            "htf_bias_accuracy": htf_accuracy,
            "param_groups": self.GROUP_DESCRIPTIONS,
            "optimizable_params": {
                name: {
                    "bounds": list(reg["bounds"]),
                    "group": reg["group"],
                    "description": reg["desc"],
                    "current": get_bot_param(name, ICT_PARAMS.get(name)),
                    "default": ICT_PARAMS.get(name),
                }
                for name, reg in self.PARAM_REGISTRY.items()
            },
            "last_check": datetime.now().isoformat(),
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  GLOBAL INSTANCE (app.py backward compat)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

self_optimizer = SelfOptimizer()
